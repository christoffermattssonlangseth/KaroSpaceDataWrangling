{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8852be01",
   "metadata": {},
   "source": [
    "# Xenium Human PE (Adult Pulmonary Fibrosis) Processing\n",
    "\n",
    "This notebook adapts the `Xenium_human_lung.ipynb` workflow for Xenium Ranger-style outputs located in:\n",
    "\n",
    "- `/Volumes/processing2/human_PE`\n",
    "\n",
    "Pipeline summary:\n",
    "\n",
    "1. Discover and load all run folders that contain Xenium Ranger `outs/` files.\n",
    "2. Merge runs into one AnnData object with per-run metadata.\n",
    "3. Run QC, filtering, normalization, PCA/UMAP, and Leiden clustering.\n",
    "4. Add spatial coordinates and inspect spatial cluster structure.\n",
    "5. Export clustered object and marker-gene tables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02652c7f",
   "metadata": {},
   "source": [
    "## 1) Imports and plotting defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f1b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Helps avoid cache-path issues in constrained environments.\n",
    "os.environ.setdefault('NUMBA_CACHE_DIR', '/tmp/numba_cache')\n",
    "os.environ.setdefault('MPLCONFIGDIR', '/tmp/matplotlib')\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sc.settings.verbosity = 2\n",
    "sc.set_figure_params(dpi=110, facecolor='white')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c398c0e",
   "metadata": {},
   "source": [
    "## 2) Configure input/output paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7f7259",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path('/Volumes/processing2/human_PE')\n",
    "OUTPUT_DIR = BASE_DIR / 'derived_scanpy'\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "RAW_PATH = OUTPUT_DIR / 'human_pe_raw.h5ad'\n",
    "CLUSTERED_PATH = OUTPUT_DIR / 'human_pe_clustered.h5ad'\n",
    "MARKER_TABLE_PATH = OUTPUT_DIR / 'human_pe_markers_leiden_1.0.csv'\n",
    "\n",
    "print('BASE_DIR:', BASE_DIR)\n",
    "print('OUTPUT_DIR:', OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb103567",
   "metadata": {},
   "source": [
    "## 3) Discover Xenium Ranger run directories\n",
    "\n",
    "A valid run folder is any direct child directory of `BASE_DIR` with:\n",
    "\n",
    "- `outs/cell_feature_matrix.h5`\n",
    "- `outs/cells.csv.gz`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16be4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_xenium_runs(base_dir: Path):\n",
    "    run_paths = []\n",
    "    for p in sorted(base_dir.iterdir()):\n",
    "        if not p.is_dir() or p.name.startswith('.') or p.name.startswith('._'):\n",
    "            continue\n",
    "        outs = p / 'outs'\n",
    "        if (outs / 'cell_feature_matrix.h5').exists() and (outs / 'cells.csv.gz').exists():\n",
    "            run_paths.append(p)\n",
    "    return run_paths\n",
    "\n",
    "run_dirs = find_xenium_runs(BASE_DIR)\n",
    "\n",
    "print(f'Found {len(run_dirs)} run directories:')\n",
    "for p in run_dirs:\n",
    "    print(' -', p.name)\n",
    "\n",
    "if len(run_dirs) == 0:\n",
    "    raise FileNotFoundError(f'No valid Xenium run directories found under {BASE_DIR}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6555fd",
   "metadata": {},
   "source": [
    "## 4) Load each run and align matrix + cell metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f4e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_sample_id(run_name: str) -> str:\n",
    "    sample_id = run_name.removesuffix('_xenium_output')\n",
    "    if sample_id.startswith('output-'):\n",
    "        sample_id = sample_id[len('output-'):]\n",
    "    return sample_id\n",
    "\n",
    "\n",
    "def load_xenium_ranger_run(run_dir: Path) -> sc.AnnData:\n",
    "    outs = run_dir / 'outs'\n",
    "    h5_path = outs / 'cell_feature_matrix.h5'\n",
    "    cells_path = outs / 'cells.csv.gz'\n",
    "\n",
    "    if not h5_path.exists() or not cells_path.exists():\n",
    "        missing = [str(p.name) for p in [h5_path, cells_path] if not p.exists()]\n",
    "        raise FileNotFoundError(f'{run_dir.name}: missing required files: {missing}')\n",
    "\n",
    "    print(f'Loading {run_dir.name}')\n",
    "    ad = sc.read_10x_h5(h5_path)\n",
    "\n",
    "    cell_info = pd.read_csv(cells_path)\n",
    "    if 'cell_id' not in cell_info.columns:\n",
    "        cell_info = pd.read_csv(cells_path, index_col=0).reset_index().rename(columns={'index': 'cell_id'})\n",
    "\n",
    "    cell_info = cell_info.drop_duplicates(subset='cell_id', keep='first').set_index('cell_id')\n",
    "\n",
    "    shared = ad.obs_names[ad.obs_names.isin(cell_info.index)]\n",
    "    dropped_from_matrix = ad.n_obs - len(shared)\n",
    "    dropped_from_cells = cell_info.shape[0] - len(shared)\n",
    "\n",
    "    if dropped_from_matrix > 0:\n",
    "        print(f'  - dropping {dropped_from_matrix} matrix barcodes not found in cells.csv.gz')\n",
    "    if dropped_from_cells > 0:\n",
    "        print(f'  - ignoring {dropped_from_cells} cells.csv.gz rows not found in matrix')\n",
    "\n",
    "    ad = ad[shared].copy()\n",
    "    ad.obs = cell_info.loc[shared].copy()\n",
    "\n",
    "    run_name = run_dir.name\n",
    "    sample_id = derive_sample_id(run_name)\n",
    "\n",
    "    ad.obs['run'] = run_name\n",
    "    ad.obs['sample_id'] = sample_id\n",
    "    ad.obs['cell_id'] = shared.astype(str)\n",
    "\n",
    "    # Guarantee unique obs names across runs after concatenation.\n",
    "    ad.obs_names = pd.Index([f'{sample_id}:{cid}' for cid in shared], name='obs_id')\n",
    "\n",
    "    ad.var_names_make_unique()\n",
    "    return ad\n",
    "\n",
    "\n",
    "ad_list = []\n",
    "for run_dir in run_dirs:\n",
    "    try:\n",
    "        ad_run = load_xenium_ranger_run(run_dir)\n",
    "        print(f'  -> loaded {ad_run.n_obs:,} cells x {ad_run.n_vars:,} genes')\n",
    "        ad_list.append(ad_run)\n",
    "    except FileNotFoundError as e:\n",
    "        print('Skipping:', e)\n",
    "\n",
    "if len(ad_list) == 0:\n",
    "    raise RuntimeError('No runs were successfully loaded. Check input folder structure.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428a56ba",
   "metadata": {},
   "source": [
    "## 5) Concatenate runs and preserve raw counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7241dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = sc.concat(ad_list, join='outer', merge='same')\n",
    "ad.var_names_make_unique()\n",
    "\n",
    "# Keep raw integer-like counts before normalization.\n",
    "ad.layers['counts'] = ad.X.copy()\n",
    "\n",
    "print(ad)\n",
    "ad.obs[['run', 'sample_id', 'cell_id']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cad190",
   "metadata": {},
   "source": [
    "## 6) QC metrics and per-sample summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc54b162",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.calculate_qc_metrics(ad, percent_top=None, log1p=False, inplace=True)\n",
    "\n",
    "qc_summary = (\n",
    "    ad.obs.groupby('sample_id')\n",
    "    .agg(\n",
    "        n_cells=('cell_id', 'count'),\n",
    "        mean_total_counts=('total_counts', 'mean'),\n",
    "        median_total_counts=('total_counts', 'median'),\n",
    "        mean_genes=('n_genes_by_counts', 'mean'),\n",
    "        median_genes=('n_genes_by_counts', 'median'),\n",
    "    )\n",
    "    .sort_values('n_cells', ascending=False)\n",
    ")\n",
    "\n",
    "qc_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c9387",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ad.obs['total_counts'].hist(bins=100, ax=axes[0])\n",
    "axes[0].set_title('Total counts per cell')\n",
    "axes[0].set_xlabel('total_counts')\n",
    "\n",
    "ad.obs['n_genes_by_counts'].hist(bins=100, ax=axes[1])\n",
    "axes[1].set_title('Genes detected per cell')\n",
    "axes[1].set_xlabel('n_genes_by_counts')\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e107386",
   "metadata": {},
   "source": [
    "## 7) Save a raw checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135d417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.write(RAW_PATH)\n",
    "print('Wrote:', RAW_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bfab90",
   "metadata": {},
   "source": [
    "## 8) Filter low-quality cells, normalize, and log-transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01208c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match thresholds used in Xenium_human_lung.ipynb.\n",
    "sc.pp.filter_cells(ad, min_counts=15)\n",
    "sc.pp.filter_cells(ad, min_genes=5)\n",
    "\n",
    "sc.pp.normalize_total(ad, target_sum=100)\n",
    "sc.pp.log1p(ad)\n",
    "\n",
    "print(ad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4979f77",
   "metadata": {},
   "source": [
    "## 9) PCA, neighborhood graph, UMAP, and Leiden clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca2fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(ad)\n",
    "sc.pl.pca_variance_ratio(ad, n_pcs=50, log=True)\n",
    "\n",
    "sc.pp.neighbors(ad, n_neighbors=15, n_pcs=30)\n",
    "sc.tl.umap(ad, min_dist=0.1)\n",
    "\n",
    "sc.pl.umap(ad, color=['sample_id'], s=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ad563",
   "metadata": {},
   "outputs": [],
   "source": [
    "resolutions = [0.1, 0.5, 1.0, 1.5, 2.0]\n",
    "\n",
    "for resolution in resolutions:\n",
    "    key = f'leiden_{resolution}'\n",
    "    if key not in ad.obs.columns:\n",
    "        sc.tl.leiden(ad, resolution=resolution, key_added=key)\n",
    "    sc.pl.umap(ad, color=key, legend_loc='on data', frameon=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22144ac",
   "metadata": {},
   "source": [
    "## 10) Add spatial coordinates and inspect spatial cluster maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d523c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.obsm['spatial'] = ad.obs[['x_centroid', 'y_centroid']].to_numpy()\n",
    "\n",
    "# Global map\n",
    "sc.pl.embedding(ad, basis='spatial', color=['sample_id', 'leiden_1.0'], s=2, frameon=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48841dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-sample spatial cluster maps\n",
    "for sid in sorted(ad.obs['sample_id'].unique()):\n",
    "    ad_sub = ad[ad.obs['sample_id'] == sid].copy()\n",
    "    sc.pl.embedding(\n",
    "        ad_sub,\n",
    "        basis='spatial',\n",
    "        color='leiden_1.0',\n",
    "        title=f'{sid} (leiden_1.0)',\n",
    "        s=2,\n",
    "        frameon=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cf16a9",
   "metadata": {},
   "source": [
    "## 11) Marker genes for cluster interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3f3ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_key = 'leiden_1.0'\n",
    "\n",
    "sc.tl.rank_genes_groups(ad, groupby=cluster_key, method='t-test')\n",
    "sc.pl.rank_genes_groups(ad, n_genes=25, sharey=False)\n",
    "\n",
    "markers = sc.get.rank_genes_groups_df(ad, group=None)\n",
    "markers = markers.sort_values(['group', 'logfoldchanges'], ascending=[True, False])\n",
    "markers.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d0adc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_markers = markers.groupby('group').head(30)\n",
    "top_markers.to_csv(MARKER_TABLE_PATH, index=False)\n",
    "print('Wrote marker table:', MARKER_TABLE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b84562",
   "metadata": {},
   "source": [
    "## 12) Save clustered AnnData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccf6d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad.write(CLUSTERED_PATH)\n",
    "print('Wrote:', CLUSTERED_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}